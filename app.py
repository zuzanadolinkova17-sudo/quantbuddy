# app.py â€” QuantBuddy (MVP)
# WebovÃ¡ appka pro zÃ¡kladnÃ­ kvantitativnÃ­ analÃ½zy s Äesky psanou interpretacÃ­.
# SpuÅ¡tÄ›nÃ­: 1) pip install -r requirements.txt  2) streamlit run app.py

import io
import tempfile
import textwrap
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf
from docx import Document
from docx.shared import Inches

# ---------------------------
# NastavenÃ­ strÃ¡nky (musÃ­ bÃ½t prvnÃ­ Streamlit pÅ™Ã­kaz)
# ---------------------------

st.set_page_config(
    page_title="QuantBuddy â€” chytrÃ½ parÅ¥Ã¡k pro analÃ½zu dat",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.markdown("""
# QuantBuddy ğŸ“Š  
*TvÅ¯j chytrÃ½ parÅ¥Ã¡k pro kvantitativnÃ­ vÃ½zkum.*  
Nahraj data â†’ vyber analÃ½zu â†’ zÃ­skej vÃ½sledky i interpretaci v ÄeÅ¡tinÄ›.
""")

# ---------------------------
# PomocnÃ© funkce
# ---------------------------

def detect_var_types(df: pd.DataFrame, cat_unique_threshold: int = 10):
    """HrubÃ¡ heuristika: text = kategorickÃ¡; ÄÃ­selnÃ¡ s <=10 unikÃ¡ty = kategorickÃ¡; jinak numerickÃ¡."""
    types = {}
    for col in df.columns:
        s = df[col]
        if pd.api.types.is_numeric_dtype(s):
            nunq = s.dropna().nunique()
            types[col] = "kategorickÃ¡" if nunq <= cat_unique_threshold else "numerickÃ¡"
        else:
            types[col] = "kategorickÃ¡"
    return types

def clean_series_pair(x: pd.Series, y: pd.Series):
    df = pd.concat([x, y], axis=1).dropna()
    return df.iloc[:,0], df.iloc[:,1]

def cohen_d_from_groups(g1, g2):
    n1, n2 = len(g1), len(g2)
    s1, s2 = np.var(g1, ddof=1), np.var(g2, ddof=1)
    sp = np.sqrt(((n1-1)*s1 + (n2-1)*s2) / (n1+n2-2))
    if sp == 0:
        return np.nan
    return (np.mean(g1) - np.mean(g2)) / sp

def cramers_v(chi2, n, r, c):
    return np.sqrt(chi2 / (n * (min(r-1, c-1))))

def eta_squared_anova(anova_table):
    try:
        ss_effect = anova_table.loc['C(group)', 'sum_sq']
        ss_resid = anova_table.loc['Residual', 'sum_sq']
        return ss_effect / (ss_effect + ss_resid)
    except Exception:
        return np.nan

def wrap(text, width=90):
    return "\n".join(textwrap.wrap(text, width=width))

# ---------------------------
# GenerÃ¡tor interpretacÃ­ (CZ)
# ---------------------------

def interpret_correlation(stat, p, n, method, varx, vary):
    sig = p < 0.05
    strength = "slabÃ½"
    absr = abs(stat)
    if absr >= 0.7:
        strength = "silnÃ½"
    elif absr >= 0.4:
        strength = "stÅ™ednÄ› silnÃ½"
    elif absr >= 0.2:
        strength = "slabÃ½"
    trend = "pozitivnÃ­" if stat > 0 else ("negativnÃ­" if stat < 0 else "nulovÃ½")

    lines = [
        f"Byla provedena {method} korelace mezi â€{varx}â€œ a â€{vary}â€œ (n = {n}).",
        f"VÃ½sledek ukazuje {strength} {trend} vztah (r = {stat:.2f}, p = {p:.3f})."
    ]
    if sig:
        lines.append("Vztah je statisticky vÃ½znamnÃ½ na hladinÄ› Î± = 0,05.")
    else:
        lines.append("Vztah nenÃ­ statisticky vÃ½znamnÃ½ na hladinÄ› Î± = 0,05.")
    lines.append("Pozn.: Korelace neimplikuje kauzalitu.")
    return " ".join(lines)

def interpret_ttest(t, p, d, n1, n2, group, outcome):
    sig = p < 0.05
    eff = ""
    if not np.isnan(d):
        mag = "malÃ½"
        if abs(d) >= 0.8:
            mag = "velkÃ½"
        elif abs(d) >= 0.5:
            mag = "stÅ™ednÃ­"
        eff = f" (Cohenovo d = {d:.2f}, {mag} efekt)."

    lines = [
        f"Byl proveden dvouvÃ½bÄ›rovÃ½ t-test pro nezÃ¡vislÃ© vÃ½bÄ›ry pro porovnÃ¡nÃ­ prÅ¯mÄ›rÅ¯ promÄ›nnÃ© â€{outcome}â€œ mezi dvÄ›ma ÃºrovnÄ›mi â€{group}â€œ (nâ‚ = {n1}, nâ‚‚ = {n2}).",
        f"VÃ½sledek: t = {t:.2f}, p = {p:.3f}{eff}"
    ]
    if sig:
        lines.append("RozdÃ­l je statisticky vÃ½znamnÃ½ na hladinÄ› Î± = 0,05.")
    else:
        lines.append("RozdÃ­l nenÃ­ statisticky vÃ½znamnÃ½ na hladinÄ› Î± = 0,05.")
    return " ".join(lines)

def interpret_chi2(chi2, p, dof, v, n, var1, var2):
    sig = p < 0.05
    mag = ""
    if not np.isnan(v):
        size = "slabÃ©"
        if v >= 0.5:
            size = "silnÃ©"
        elif v >= 0.3:
            size = "stÅ™ednÃ­"
        mag = f" Velikost asociace dle Cramerova V = {v:.2f} ({size})."
    lines = [
        f"Byl proveden chÃ­-kvadrÃ¡t test nezÃ¡vislosti pro â€{var1}â€œ Ã— â€{var2}â€œ (n = {n}, df = {dof}).",
        f"VÃ½sledek: Ï‡Â² = {chi2:.2f}, p = {p:.3f}.{mag}"
    ]
    if sig:
        lines.append("Mezi kategoriemi existuje statisticky vÃ½znamnÃ¡ asociace.")
    else:
        lines.append("Statisticky vÃ½znamnÃ¡ asociace mezi promÄ›nnÃ½mi nebyla zjiÅ¡tÄ›na.")
    return " ".join(lines)

def interpret_anova(F, p, eta2, k, n, group, outcome):
    sig = p < 0.05
    mag = ""
    if not np.isnan(eta2):
        size = "malÃ½"
        if eta2 >= 0.14:
            size = "velkÃ½"
        elif eta2 >= 0.06:
            size = "stÅ™ednÃ­"
        mag = f" (Î·Â² = {eta2:.2f}, {size} efekt)."
    lines = [
        f"JednofaktorovÃ¡ ANOVA pro â€{outcome}â€œ napÅ™Ã­Ä {k} skupinami promÄ›nnÃ© â€{group}â€œ (n = {n}).",
        f"VÃ½sledek: F = {F:.2f}, p = {p:.3f}{mag}"
    ]
    if sig:
        lines.append("RozdÃ­ly mezi alespoÅˆ dvÄ›ma skupinami jsou statisticky vÃ½znamnÃ©.")
    else:
        lines.append("Statisticky vÃ½znamnÃ© rozdÃ­ly mezi skupinami nebyly zjiÅ¡tÄ›ny.")
    return " ".join(lines)

# ---------------------------
# Export do DOCX
# ---------------------------

def build_docx(report_title, meta, results_text, fig_bytes=None):
    doc = Document()
    doc.add_heading(report_title, level=1)
    doc.add_paragraph(f"Datum: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
    doc.add_heading("Popis dat", level=2)
    doc.add_paragraph(meta)

    doc.add_heading("VÃ½sledky a interpretace", level=2)
    for para in textwrap.wrap(results_text, width=100):
        doc.add_paragraph(para)

    if fig_bytes is not None:
        doc.add_heading("Vizualizace", level=2)
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
            tmp.write(fig_bytes.getvalue())
            tmp.flush()
            doc.add_picture(tmp.name, width=Inches(5.5))
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ---------------------------
# UI
# ---------------------------



with st.sidebar:
    st.header("1) Nahraj data")
    file = st.file_uploader("CSV nebo Excel (.xlsx)", type=["csv", "xlsx"])
    if file and file.name.lower().endswith(".xlsx"):
        try:
            xls = pd.ExcelFile(file)
            sheet_name = st.selectbox("Vyber list", xls.sheet_names)
            df = pd.read_excel(file, sheet_name=sheet_name)
        except Exception as e:
            st.error(f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ Excelu: {e}")
            df = None
    elif file and file.name.lower().endswith(".csv"):
        try:
            df = pd.read_csv(file)
        except Exception:
            file.seek(0)
            df = pd.read_csv(file, sep=";")
    else:
        df = None

    st.header("2) Zvol analÃ½zu")
    analysis = st.selectbox(
        "Typ analÃ½zy",
        [
            "Korelace dvou promÄ›nnÃ½ch",
            "PorovnÃ¡nÃ­ dvou skupin (t-test)",
            "Asociace dvou kategoriÃ¡lnÃ­ch (Ï‡Â²)",
            "PorovnÃ¡nÃ­ vÃ­ce skupin (ANOVA)",
        ],
    )

if df is None:
    st.info("Nahraj prosÃ­m datovÃ½ soubor (CSV/XLSX).")
    st.stop()

st.success(f"NaÄteno: {df.shape[0]} Å™Ã¡dkÅ¯ Ã— {df.shape[1]} sloupcÅ¯")
types = detect_var_types(df)

with st.expander("NÃ¡hled dat a typÅ¯ promÄ›nnÃ½ch", expanded=False):
    st.dataframe(df.head(10))
    typemap = pd.DataFrame({"promÄ›nnÃ¡": list(types.keys()), "typ": list(types.values())})
    st.dataframe(typemap)

# ---------------------------
# AnalÃ½zy
# ---------------------------

result_text = ""
fig_buf = None
meta_desc = f"PoÄet Å™Ã¡dkÅ¯: {df.shape[0]}, poÄet promÄ›nnÃ½ch: {df.shape[1]}."

if analysis == "Korelace dvou promÄ›nnÃ½ch":
    num_cols = [c for c,t in types.items() if t == "numerickÃ¡"]
    if len(num_cols) < 2:
        st.error("Pro korelaci jsou potÅ™eba alespoÅˆ 2 numerickÃ© promÄ›nnÃ©.")
        st.stop()
    x = st.selectbox("PromÄ›nnÃ¡ X", num_cols, index=0)
    y = st.selectbox("PromÄ›nnÃ¡ Y", num_cols, index=min(1, len(num_cols)-1))
    method = st.radio("Metoda korelace", ["Pearson", "Spearman"], horizontal=True)

    if st.button("Spustit analÃ½zu"):
        sx, sy = clean_series_pair(df[x], df[y])
        if len(sx) < 5:
            st.error("PÅ™Ã­liÅ¡ mÃ¡lo platnÃ½ch pozorovÃ¡nÃ­ (min. 5).")
            st.stop()
        if method == "Pearson":
            r, p = stats.pearsonr(sx, sy)
        else:
            r, p = stats.spearmanr(sx, sy)
        result_text = interpret_correlation(r, p, len(sx), method.lower(), x, y)

        fig, ax = plt.subplots()
        ax.scatter(sx, sy)
        ax.set_xlabel(x)
        ax.set_ylabel(y)
        ax.set_title(f"RozptylovÃ½ graf: {x} Ã— {y}")
        fig_buf = io.BytesIO()
        fig.savefig(fig_buf, format="png", bbox_inches="tight")
        st.pyplot(fig)

        st.subheader("Interpretace")
        st.write(wrap(result_text))

# (zbytek kÃ³du pokraÄuje stejnÄ› jako pÅ™edtÃ­m â€“ t-test, Ï‡Â², ANOVA, export do DOCX)
